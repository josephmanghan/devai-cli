# Research Prompt: SLM Capabilities & Constraints for Developer Productivity

**Created:** 2025-11-11
**Purpose:** Deep research on SLM capabilities, constraints, and characteristics before brainstorming app ideas
**Target:** Gemini (or similar advanced LLM for research)

---

I'm brainstorming app ideas for a locally-run Small Language Model (SLM) focused on productivity for software developers. Before I can generate app ideas, I need deep research on SLM capabilities, constraints, and characteristics.

**What I already know about SLMs:**

- Much smaller than regular Large Language Models
- Run on significantly less compute
- Can run locally on a laptop (not cloud-based)
- Have small context size limitations (context management is critical)
- More powerful hardware = more context possible, but still limited compared to cloud models

**I need comprehensive research on the following questions:**

### SLM Capabilities & Limitations

- What tasks are SLMs actually good at vs. what they struggle with?
- What's the "sweet spot" for SLM use cases?
- How do SLM capabilities compare to cloud models for productivity tasks?
- What can SLMs do well with limited context?
- What types of tasks require too much context for SLMs?
- What's the quality difference between SLM outputs and cloud LLM outputs for the same task?
- Are SLMs better at certain types of reasoning (logical, creative, analytical)?
- What do SLMs consistently fail at that cloud models handle well?
- How do SLMs handle multi-step tasks vs. single-step tasks?
- What's the latency/response time reality for local SLMs?

### SLM Context Management

- What are effective strategies for managing small context windows?
- How can we chunk or prioritize information for SLMs?
- What patterns work well for context-efficient workflows?
- How do different SLM models compare in context handling?
- How do SLMs handle conversational context vs. one-off queries?
- What happens when you hit context limits mid-conversation?

### SLM Characteristics & Performance

- What are the typical model sizes (parameters) for SLMs?
- What hardware requirements do different SLM models have?
- How fast are SLM responses compared to cloud models?
- What are the trade-offs between model size and capability?
- Are there specific SLM models that excel at certain tasks?
- What's the personality or "feel" of working with an SLM vs. a cloud model?
- Are there tasks where SLMs are "good enough" even if not perfect?
- What makes an SLM experience different from a cloud AI experience?
- Are there use cases where SLMs might actually be preferable to cloud models?

### SLM Practical Implementation

- What are the real-world constraints of running SLMs locally (memory, CPU, battery)?
- How do you handle model updates or switching between SLM models?
- What's the setup complexity for getting an SLM running locally?
- Are there security/privacy advantages that come with local-only SLMs?
- How do SLMs handle follow-up questions or clarifications?
- What's the best way to structure prompts for SLMs given their limitations?
- Are there interaction patterns that work better with SLMs than cloud models?

### SLM Training & Knowledge

- What knowledge cutoff dates do SLMs typically have?
- How do SLMs handle domain-specific knowledge vs. general knowledge?
- Can SLMs be fine-tuned or customized for specific use cases?
- What's the knowledge gap between SLMs and larger models?
- Are there tasks where SLMs' knowledge limitations actually don't matter?

### SLM Ecosystem & Tools

- What tools/frameworks exist for running SLMs locally?
- What's the current state of the SLM ecosystem (models, tools, community)?
- Are there established best practices for SLM integration?
- What are the common pain points developers face when working with SLMs?

**Please provide comprehensive, detailed answers to these questions. Focus on practical, actionable insights that will help me understand:**

1. What SLMs are actually capable of (their strengths)
2. What SLMs struggle with (their limitations)
3. The "aesthetic" or character of working with SLMs
4. Real-world constraints and considerations
5. Current state of the SLM ecosystem

This research will inform app ideation for productivity-focused SLM applications.

---

**Expected Output Format:**

- Structured responses for each category
- Practical examples and use cases
- Specific model recommendations (if applicable)
- Implementation considerations
- Developer workflow integration opportunities
