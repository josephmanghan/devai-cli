<story-context id="2-5-1-implement-base-model-auto-pull" v="1.0">
  <metadata>
    <epicId>2</epicId>
    <storyId>5.1</storyId>
    <title>Implement Base Model Auto-Pull</title>
    <status>ready-for-dev</status>
    <generatedAt>2025-12-01</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>dev/sprint-artifacts/2-5-1-implement-base-model-auto-pull.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>developer</asA>
    <iWant>the `ollatool setup` command to automatically pull the base model if it's missing</iWant>
    <soThat>users don't need to manually download models during initial setup</soThat>
    <tasks>
- [ ] Update LlmPort interface (AC: 1)
  - [ ] Add clean pullModel method signature: `pullModel(modelName: string): Promise<void>`
  - [ ] Add JSDoc documentation noting it returns raw progress data (no UI)
- [ ] Implement OllamaAdapter pullModel method (AC: 2)
  - [ ] Add pullModel implementation using ollama SDK pull() method
  - [ ] Return raw progress data stream - NO ora spinners or console output
  - [ ] Add idempotency check using existing checkModel() pattern
- [ ] Update SetupCommand base model validation (AC: 3, 4, 5, 6)
  - [ ] Modify handleBaseModelResult() to auto-pull when baseModelExists is false
  - [ ] Add UI layer: ora spinner for pull progress using adapter's raw data
  - [ ] Update user messaging for auto-pull scenarios with progress display
  - [ ] Add fallback messaging for pull failures with manual command guidance
- [ ] Add comprehensive unit tests (AC: 8, 9)
  - [ ] Test OllamaAdapter.pullModel() with raw stream data (no UI)
  - [ ] Test SetupCommand.handleBaseModelResult() auto-pull with UI layer
  - [ ] Test pullModel idempotency when model already exists
  - [ ] Test pullModel error handling and graceful failure scenarios
  - [ ] Mock streaming progress responses using createMockAsyncIterator helper
  - [ ] Mock console operations: vi.spyOn(console, 'log').mockImplementation(() => {})
  - [ ] Restore mocks in afterEach: vi.restoreAllMocks()
- [ ] Add integration testing with small model (AC: 10, 11)
  - [ ] Create integration test using smollm:135m (tiny model)
  - [ ] Test end-to-end auto-pull workflow in setup command
  - [ ] Clean up test model in afterEach/afterAll using ollamaClient.delete()
  - [ ] Verify qwen2.5-coder:1.5b is NEVER used in integration tests
- [ ] Update error handling and messaging (AC: 5, 6)
  - [ ] Add pull-specific error handling with user-friendly messages
  - [ ] Include manual pull fallback: "ollama pull ${modelName}"
  - [ ] Add Ctrl+C exit guidance for long-running operations
- [ ] Run `npm run pr` to validate implementation is ready for PR
    </tasks>
  </story>

  <acceptanceCriteria>
1. [ ] LlmPort interface updated with `pullModel(modelName: string)` method (NO UI parameters)
2. [ ] OllamaAdapter implements clean `pullModel()` returning raw progress stream (NO ora/console)
3. [ ] SetupCommand.handleBaseModelResult() modified to auto-pull missing base model with UI feedback (making use of /ui layer)
4. [ ] Progress shows model name dynamically: "Pulling ${modelName}... ${percentage}% (${downloaded}MB/${total}MB)"
5. [ ] Graceful exit handling with "Press Ctrl+C to exit" message for long-running operations
6. [ ] Fallback error message with manual pull command if auto-pull fails
7. [ ] Implementation is idempotent (safe to re-run, skips if model already exists)
8. [ ] Unit tests added for clean pullModel (adapter) and SetupCommand UI handling (separated)
9. [ ] Console operations mocked in tests (vi.spyOn(console, 'log').mockImplementation(() => {}))
10. [ ] Integration test added using `smollm:135m` model with cleanup in afterEach
11. [ ] Integration test NEVER uses `qwen2.5-coder:1.5b` to avoid large downloads
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc path="dev/stories/epic-2-ollama-integration.md" title="Epic 2: Ollama Integration & Model Management" section="Story 2.5.1" snippet="Story 2.5.1: Implement Base Model Auto-Pull. As a developer, I want the ollatool setup command to automatically pull the base model if it's missing, so that users don't need to manually download models during initial setup. Acceptance Criteria include: LlmPort interface updated with pullModel method, OllamaAdapter implements pullModel with streaming progress, SetupCommand modified to auto-pull base model instead of erroring, progress shows model name dynamically with percentage and MB downloaded, graceful exit handling, fallback error message, idempotent implementation, unit tests with mocked streaming progress, integration test using smollm:135m model."/>
      <doc path="dev/architecture.md" title="Architecture Document" section="Ollama Model Architecture" snippet="Custom Model Instance: ollatool-commit. Base Model: qwen2.5-coder:1.5b (quantized). Creation Method: Direct SDK parameter configuration (NOT Modelfile parsing). CLI vs JS SDK Fundamental Difference: Ollama CLI uses Modelfile parsing, JS SDK uses direct parameter passing."/>
      <doc path="dev/architecture.md" title="Architecture Document" section="Setup Command Implementation" snippet="Setup Operations (with conditional checks): 1. Pull base model: qwen2.5-coder:1.5b. Check: ollama.list() - does qwen2.5-coder:1.5b exist? If exists: Skip pull, display [INFO] Base model already present âœ“. If missing: ollama pull qwen2.5-coder:1.5b with progress bar."/>
    </docs>
    <code>
      <code path="src/core/ports/llm-port.ts" kind="interface" symbol="LlmPort" lines="1-44" reason="Core LLM port interface that needs to be extended with pullModel method. Current methods include checkConnection(), checkModel(), createModel(), and generate(). This is where pullModel(modelName: string) needs to be added."/>
      <code path="src/infrastructure/llm/ollama-adapter.ts" kind="adapter" symbol="OllamaAdapter" lines="16-196" reason="Main Ollama adapter implementing LlmPort. Contains existing patterns for model operations, error handling, and streaming progress (see createModel implementation with spinner). This class needs pullModel implementation using ollama SDK pull() method with streaming support."/>
      <code path="src/features/setup/setup-command.ts" kind="command" symbol="SetupCommand" lines="103-143" reason="Setup command handler with handleBaseModelResult() method that currently throws ValidationError when base model missing. This method needs to be modified to auto-pull missing base model using adapter.pullModel() with UI feedback."/>
      <code path="src/infrastructure/llm/ollama-adapter.ts" kind="method" symbol="modelAlreadyExists" lines="76-83" reason="Existing idempotency check pattern using checkModel() method. This pattern should be reused for pullModel implementation to ensure safe re-execution when model already exists."/>
      <code path="src/infrastructure/llm/ollama-adapter.ts" kind="method" symbol="processCreationStream" lines="186-195" reason="Existing streaming progress handling pattern for model creation. Shows how to process streaming progress updates and update spinner text dynamically - similar pattern needed for pull progress."/>
    </code>
    <dependencies>
      <node ecosystem="nodejs" version=">=20.0.0" packages="commander@14.0.2, ora@9.0.0, ollama@0.6.3"/>
      <testing ecosystem="vitest" packages="vitest@4.0.14, @vitest/coverage-v8@4.0.14"/>
      <devtools ecosystem="typescript" packages="typescript@5.9.3, tsup@latest, tsx@latest"/>
    </dependencies>
  </artifacts>

  <constraints>
    - Follow hexagonal architecture patterns: LlmPort interface defines contract, OllamaAdapter implements with clean SDK integration, SetupCommand handles UI layer
    - Maintain existing error handling patterns using AppError classes (SystemError, ValidationError, UserError)
    - Use ora spinner for all user-facing progress updates in UI layer
    - Keep adapter methods clean (no console output) - UI concerns handled by command layer
    - Implement idempotency using existing checkModel() pattern before attempting pull
  </constraints>
  <interfaces>
    <interface name="LlmPort" kind="port" signature="pullModel(modelName: string): Promise<void>" path="src/core/ports/llm-port.ts"/>
  </interfaces>
  <tests>
    <standards>
      Unit tests use Vitest with vi.mock() for external dependencies. Console operations mocked with vi.spyOn(console, 'log').mockImplementation(() => {}) and restored with vi.restoreAllMocks(). Streaming responses mocked using createMockAsyncIterator helper from existing test files.
    </standards>
    <locations>
      - Unit tests: Co-located with source files (*.test.ts)
      - Integration tests: tests/integration/ directory
      - Test patterns: tests/helpers/ directory for mock factories
    </locations>
    <ideas>
      <test ac="1" idea="Test LlmPort interface compiles with pullModel method added"/>
      <test ac="2" idea="Test OllamaAdapter.pullModel() calls ollamaClient.pull() with correct parameters and streams progress without UI"/>
      <test ac="3" idea="Test SetupCommand.handleBaseModelResult() calls adapter.pullModel() when baseModelExists is false and shows ora spinner with progress"/>
      <test ac="4" idea="Test progress display format: 'Pulling modelName... X% (downloadedMB/totalMB)' using mock progress stream data"/>
      <test ac="5" idea="Test graceful exit with 'Press Ctrl+C to exit' message for long-running pulls"/>
      <test ac="6" idea="Test fallback error message with manual pull command if auto-pull fails"/>
      <test ac="7" idea="Test idempotency: pullModel() skips when model already exists using checkModel() pattern"/>
      <test ac="8" idea="Test pullModel error handling with network failures and SDK errors"/>
      <test ac="9" idea="Unit test with mocked console operations: vi.spyOn(console, 'log').mockImplementation(() => {})"/>
      <test ac="10" idea="Integration test using smollm:135m model (tiny, fast download) with ollamaClient.delete() cleanup in afterEach"/>
      <test ac="11" idea="Test validation: qwen2.5-coder:1.5b NEVER used in integration tests to avoid large downloads"/>
    </ideas>
  </tests>
</story-context>